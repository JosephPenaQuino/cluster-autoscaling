\section{Methodology}

This section describes the tools, technologies, and procedures employed in conducting the experiments.
A Github repository was created to store the scripts and configurations used in the experiments \githubLink{}.
The evaluation is divided into two parts: the first part involves experimentation on a local computer using Minikube as main tool, while the second part focuses on experimentation within a cloud environment using AWS EKS.

\subsection{Minikube procedure}
% Some introduction
The following methodology is based on the tutorial \textit{Horizontal Pod Autoscaler Walkthrough}~\cite{KubernetesHpaWalkthrough}, which consists in setting up a deployment on a local computer using Minikube; then, the HPA is configured to scale the deployment based on CPU usage; an external script is used to simulate a load on the deployment; finally, the script is stopped.
This subsection describes the steps to reproduce the experiment.

% Description of the computer and software versions
The computer used for the local experimentations runs a \operatingSystem{} in an \cpuModel{} processor with \cpuCores{} cores and \cpuRam{}~GB of RAM.
The version of \texttt{minikube} is \minikubeVersion{}, \texttt{kubectl} client is \kubectlClientVersion{}, \texttt{kubectl} server is \kubectlServerVersion{}, and \texttt{kustomize} is \kubectlKustomizeVersion{}.

\subsubsection{Kubernetes Cluster Configuration}
The experiment is run on a local Kubernetes cluster using Minikube.
To start the Minikube cluster, run the command from Listing~\ref{lst:minikube-cluster}.
This command should create three nodes, where two nodes are worker nodes and one node is the control plane.

\begin{lstlisting}[language=bash, label={lst:minikube-cluster},caption={Starting the Minikube cluster}]
  minikube start --nodes 3 -p multinode --cpus 3 --memory 2048
\end{lstlisting}

\subsubsection{PHP Apache Server Deployment}
The next step is to deploy a PHP Apache server on the Minikube cluster.
This deployment is described in Appendix~\ref{appendix:php_apache}.
The command in Listing~\ref{lst:kubectl_php_apache} deploys the PHP Apache server on the Minikube cluster.
The YAML file contains the description of two resources: a deployment that runs a php server from the image \texttt{registry.k8s.io/hpa-example} and a service that exposes the deployment.

\begin{lstlisting}[language=bash, label={lst:kubectl_php_apache},caption={Deploying the PHP Apache server}]
  kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
\end{lstlisting}

\subsubsection{Configuration of Horizontal Pod Autoscaler}
The Horizontal Pod Autoscaler (HPA) is configured to scale the PHP Apache server deployment based on CPU usage.
The command in Listing~\ref{lst:kubectl_hpa} creates an HPA that scales the PHP Apache server deployment to maintain an average CPU utilization of 50\%.

\begin{lstlisting}[language=bash, label={lst:kubectl_hpa},caption={Configuring the Horizontal Pod Autoscaler}]
  kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
\end{lstlisting}


\subsubsection{Increasing and Decreasing Load}
To test the HPA, a script is used to simulate a load on the PHP Apache server deployment.
A command that requests the PHP Apache server is run in a loop to increase the CPU usage.
The command in Listing~\ref{lst:kubectl_load} runs the script that simulates the load.

\begin{lstlisting}[language=bash, label={lst:kubectl_load},caption={Simulating the load}]
  kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"

\end{lstlisting}

\subsection{AWS EKS procedure}

This subsection outlines the step-by-step procedure to implement a Horizontal Pod Autoscaler (HPA) in an Amazon Elastic Kubernetes Service (EKS) cluster, based on the official AWS tutorial \textit{Horizontal Pod Autoscaler Walkthrough}~\cite{AwsHorizontalPodAutoescaler}. All commands the was used to execute this procedure are described in Appendix~\ref{appendix:deploy_eks}.

\subsubsection{Environment Setup}

To begin, ensure that the environment is correctly configured. The prerequisites include having the AWS Command Line Interface (CLI) and `kubectl` installed and properly configured. Additionally, ensure that the IAM user or role has the necessary permissions to interact with Amazon EKS.

First, verify that the EKS cluster is up and running by updating the kubeconfig. Next, it is essential to deploy the Kubernetes Metrics Server, which is a prerequisite for the Horizontal Pod Autoscaler to function correctly. The Metrics Server collects metrics about resource usage and exposes them to the Kubernetes API server.

Deploy the Metrics Server and verify the deployment by checking the status of the Metrics Server.

\subsubsection{Deploying a Sample Application}

With the environment set up, the next step is to deploy a sample application that will be scaled by the Horizontal Pod Autoscaler. The AWS tutorial uses a simple PHP-Apache web server application.

Deploy a sample PHP-Apache web server application:

\begin{lstlisting}[language=bash, label={lst:deploy-application}, caption={Deploying PHP application}]
kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
\end{lstlisting}

This command applies a YAML file that defines the deployment and service specifications for the PHP-Apache application.

\subsubsection{Configuring the Horizontal Pod Autoscaler}

Once the application is deployed, the next step is to create the Horizontal Pod Autoscaler. The HPA automatically adjusts the number of pods in a deployment based on observed CPU utilization or other select metrics.

Create the Horizontal Pod Autoscaler for the deployed application, the HPA is configured to maintain the average CPU utilization of the pods in the `php-apache` deployment at 50\%. If the CPU utilization exceeds this target, the HPA will scale up the number of pods, with a minimum of 1 and a maximum of 10 replicas.

\subsubsection{Testing the Autoscaler}

To validate the functionality of the Horizontal Pod Autoscaler, generate a load on the application using the following command:

\begin{lstlisting}[language=bash, label={lst:autoscaler-test}, caption={Autoscaler test}]
kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"
\end{lstlisting}

This will continuously send requests to the PHP-Apache application, increasing its CPU usage and triggering the HPA to scale the pods. Observe the number of pods to ensure they scale appropriately:

\begin{lstlisting}[language=bash, label={lst:pods-number}, caption={Get the number of pods}]
kubectl get pods
\end{lstlisting}

\subsubsection{Verification and Cleanup}

Finally, verify that the Horizontal Pod Autoscaler is functioning as expected by analyzing the HPA status and the number of pods in the deployment. Once the testing is complete, it is important to clean up the resources to avoid unnecessary AWS charges.
