\section{Methodology}

This section describes the tools, technologies, and procedures employed in conducting the experiments.
The evaluation is divided into two parts: the first part involves experimentation on a local computer using Minikube as main tool, while the second part focuses on experimentation within a cloud environment using AWS EKS.

\subsection{Minikube procedure}
% Some introduction
The following methodology is based on the tutorial \textit{Horizontal Pod Autoscaler Walkthrough}~\cite{KubernetesHpaWalkthrough}, which consists in setting up a deployment on a local computer using Minikube; then, the HPA is configured to scale the deployment based on CPU usage; an external script is used to simulate a load on the deployment; finally, the script is stopped.
This subsection describes the steps to reproduce the experiment.

% Step 1: Configuring Kubernetes cluster configuration



% Procedure

% Description of the computer and software versions
The computer used for the local experimentations runs a \operatingSystem{} in an \cpuModel{} processor with \cpuCores{} cores and \cpuRam{}~GB of RAM.
The version of \texttt{minikube} is \minikubeVersion{}, \texttt{kubectl} client is \kubectlClientVersion{}, \texttt{kubectl} server is \kubectlServerVersion{}, and \texttt{kustomize} is \kubectlKustomizeVersion{}.

\subsection{AWS EKS procedure} % Fabio

This subsection outlines the step-by-step procedure to implement a Horizontal Pod Autoscaler (HPA) in an Amazon Elastic Kubernetes Service (EKS) cluster, based on the official AWS tutorial \textit{Horizontal Pod Autoscaler Walkthrough}~\cite{AwsHorizontalPodAutoescaler}.

\subsubsection{Environment Setup}

To begin, ensure that your environment is correctly configured. The prerequisites include having the AWS Command Line Interface (CLI) and `kubectl` installed and properly configured. Additionally, ensure that your IAM user or role has the necessary permissions to interact with Amazon EKS.

First, verify that your EKS cluster is up and running by using the following command:

\begin{lstlisting}[language=bash]
aws eks --region us-east-1 update-kubeconfig --name my-cluster
\end{lstlisting}

Next, it is essential to deploy the Kubernetes Metrics Server, which is a prerequisite for the Horizontal Pod Autoscaler to function correctly. The Metrics Server collects metrics about resource usage and exposes them to the Kubernetes API server.

Deploy the Metrics Server using the following commands:

\begin{lstlisting}[language=bash]
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
\end{lstlisting}

Verify the deployment by checking the status of the Metrics Server:

\begin{lstlisting}[language=bash]
kubectl get deployment metrics-server -n kube-system
\end{lstlisting}

\subsubsection{Deploying a Sample Application}

With the environment set up, the next step is to deploy a sample application that will be scaled by the Horizontal Pod Autoscaler. The AWS tutorial uses a simple PHP-Apache web server application.

Deploy the application using the following command:

\begin{lstlisting}[language=bash]
kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
\end{lstlisting}

This command applies a YAML file that defines the deployment and service specifications for the PHP-Apache application.

\subsubsection{Configuring the Horizontal Pod Autoscaler}

Once the application is deployed, the next step is to create the Horizontal Pod Autoscaler. The HPA automatically adjusts the number of pods in a deployment based on observed CPU utilization or other select metrics.

Create the HPA using the command:

\begin{lstlisting}[language=bash]
kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
\end{lstlisting}

In this example, the HPA is configured to maintain the average CPU utilization of the pods in the `php-apache` deployment at 50\%. If the CPU utilization exceeds this target, the HPA will scale up the number of pods, with a minimum of 1 and a maximum of 10 replicas.

\subsubsection{Testing the Autoscaler}

To validate the functionality of the Horizontal Pod Autoscaler, generate a load on the application using the following command:

\begin{lstlisting}[language=bash]
kubectl run -i --tty load-generator --image=busybox /bin/sh
while true; do wget -q -O- http://php-apache.default.svc.cluster.local; done
\end{lstlisting}

This will continuously send requests to the PHP-Apache application, increasing its CPU usage and triggering the HPA to scale the pods. Monitor the HPA status with:

\begin{lstlisting}[language=bash]
kubectl get hpa
\end{lstlisting}

Also, observe the number of pods to ensure they scale appropriately:

\begin{lstlisting}[language=bash]
kubectl get pods
\end{lstlisting}

\subsubsection{Verification and Cleanup}

Finally, verify that the Horizontal Pod Autoscaler is functioning as expected by analyzing the HPA status and the number of pods in the deployment. Once the testing is complete, it is important to clean up the resources to avoid unnecessary AWS charges.

Delete the sample application and the HPA using the following commands:

\begin{lstlisting}[language=bash]
kubectl delete deployment php-apache
kubectl delete hpa php-apache
\end{lstlisting}

Additionally, you may want to remove the Metrics Server if it is no longer needed:

\begin{lstlisting}[language=bash]
kubectl delete -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
\end{lstlisting}

By following these steps, you will have successfully implemented and tested a Horizontal Pod Autoscaler in an Amazon EKS cluster.