\section{Methodology}

This section outlines the tools, technologies, and procedures utilized to conduct the experiments to evaluate the Horizontal Pod Autoscaler.
A GitHub repository was established to store the scripts and configurations used in the experiments \githubLink{}.
The evaluation is divided into two phases: the first involves experimentation on a local computer using Minikube, while the second focuses on experimentation within a cloud environment using AWS EKS.

\subsection{Minikube Procedure}

The methodology is based on the tutorial \textit{Horizontal Pod Autoscaler Walkthrough}~\cite{KubernetesHpaWalkthrough}, which involves setting up a deployment on a local computer using Minikube. The Horizontal Pod Autoscaler (HPA) is then configured to scale the deployment based on CPU usage. An external script is employed to simulate load on the deployment, and subsequently, the script is terminated. This subsection details the steps necessary to reproduce the experiment.

\paragraph{System Specifications.} The local experiments were conducted on a computer running \operatingSystem{}, running in an \cpuModel{} processor featuring \cpuCores{} cores and \cpuRam{}~GB of RAM. The versions of the software tools used are as follows: \texttt{minikube} \minikubeVersion{}, \texttt{kubectl} client \kubectlClientVersion{}, \texttt{kubectl} server \kubectlServerVersion{}, and \texttt{kustomize} \kubectlKustomizeVersion{}.

\subsubsection{Kubernetes Cluster Configuration}

The experiment was conducted on a local Kubernetes cluster using Minikube. The Minikube cluster is initiated by running the command in Listing~\ref{lst:minikube-cluster}. This command creates a cluster with three nodes: two worker nodes and one control plane node.

\begin{lstlisting}[language=bash, label={lst:minikube-cluster},caption={Starting the Minikube cluster}]
  minikube start --nodes 3 -p multinode --cpus 3 --memory 2048
\end{lstlisting}

\subsubsection{PHP Apache Server Deployment}

The next step is to deploy a PHP Apache server on the Minikube cluster. The deployment is detailed in Appendix~\ref{appendix:php_apache}. The command shown in Listing~\ref{lst:kubectl_php_apache} deploys the PHP Apache server. The YAML file used describes two resources: a deployment that runs a PHP server from the image \texttt{registry.k8s.io/hpa-example} and a service that exposes the deployment.

\begin{lstlisting}[language=bash, label={lst:kubectl_php_apache},caption={Deploying the PHP Apache server}]
  kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
\end{lstlisting}

\subsubsection{Horizontal Pod Autoscaler Configuration}

The Horizontal Pod Autoscaler (HPA) is configured to scale the PHP Apache server deployment based on CPU usage. The command in Listing~\ref{lst:kubectl_hpa} creates an HPA that scales the deployment to maintain an average CPU utilization of 50\%.

\begin{lstlisting}[language=bash, label={lst:kubectl_hpa},caption={Configuring the Horizontal Pod Autoscaler}]
  kubectl autoscale deployment php-apache --cpu-percent=50 --min=1 --max=10
\end{lstlisting}

\subsubsection{Load Testing}

To evaluate the HPA, a script is employed to simulate load on the PHP Apache server deployment. The command in Listing~\ref{lst:kubectl_load} runs the script in a loop to increase CPU usage.

\begin{lstlisting}[language=bash, label={lst:kubectl_load},caption={Simulating the load}]
  kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"
\end{lstlisting}

\subsection{AWS EKS procedure}

This subsection outlines the step-by-step procedure to implement a Horizontal Pod Autoscaler (HPA) in an Amazon Elastic Kubernetes Service (EKS) cluster, based on the official AWS tutorial \textit{Horizontal Pod Autoscaler Walkthrough}~\cite{AwsHorizontalPodAutoescaler}. All commands the was used to execute this procedure are described in Appendix~\ref{appendix:deploy_eks}.

\subsubsection{Environment Setup}

To begin, ensure that the environment is correctly configured. The prerequisites include having the AWS Command Line Interface (CLI) and `kubectl` installed and properly configured. Additionally, ensure that the IAM user or role has the necessary permissions to interact with Amazon EKS.

First, verify that the EKS cluster is up and running by updating the kubeconfig. Next, it is essential to deploy the Kubernetes Metrics Server, which is a prerequisite for the Horizontal Pod Autoscaler to function correctly. The Metrics Server collects metrics about resource usage and exposes them to the Kubernetes API server.

Deploy the Metrics Server and verify the deployment by checking the status of the Metrics Server.

\subsubsection{Deploying a Sample Application}

With the environment set up, the next step is to deploy a sample application that will be scaled by the Horizontal Pod Autoscaler. The AWS tutorial uses a simple PHP-Apache web server application.

Deploy a sample PHP-Apache web server application:

\begin{lstlisting}[language=bash, label={lst:deploy-application}, caption={Deploying PHP application}]
kubectl apply -f https://k8s.io/examples/application/php-apache.yaml
\end{lstlisting}

This command applies a YAML file that defines the deployment and service specifications for the PHP-Apache application.

\subsubsection{Configuring the Horizontal Pod Autoscaler}

Once the application is deployed, the next step is to create the Horizontal Pod Autoscaler. The HPA automatically adjusts the number of pods in a deployment based on observed CPU utilization or other select metrics.

Create the Horizontal Pod Autoscaler for the deployed application, the HPA is configured to maintain the average CPU utilization of the pods in the `php-apache` deployment at 50\%. If the CPU utilization exceeds this target, the HPA will scale up the number of pods, with a minimum of 1 and a maximum of 10 replicas.

\subsubsection{Testing the Autoscaler}

To validate the functionality of the Horizontal Pod Autoscaler, generate a load on the application using the following command:

\begin{lstlisting}[language=bash, label={lst:autoscaler-test}, caption={Autoscaler test}]
kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://php-apache; done"
\end{lstlisting}

This will continuously send requests to the PHP-Apache application, increasing its CPU usage and triggering the HPA to scale the pods. Observe the number of pods to ensure they scale appropriately:

\begin{lstlisting}[language=bash, label={lst:pods-number}, caption={Get the number of pods}]
kubectl get pods
\end{lstlisting}

\subsubsection{Verification and Cleanup}

Finally, verify that the Horizontal Pod Autoscaler is functioning as expected by analyzing the HPA status and the number of pods in the deployment. Once the testing is complete, it is important to clean up the resources to avoid unnecessary AWS charges.
